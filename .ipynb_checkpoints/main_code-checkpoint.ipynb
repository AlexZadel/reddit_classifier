{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Using Reddit's API for Predicting Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T19:28:02.619411Z",
     "start_time": "2017-10-23T19:28:02.600856Z"
    }
   },
   "source": [
    "In this project, we will practice two major skills. Collecting data via an API request and then building a binary predictor.\n",
    "\n",
    "As we discussed in week 2, and earlier today, there are two components to starting a data science problem: the problem statement, and acquiring the data.\n",
    "\n",
    "For this article, your problem statement will be: _What characteristics of a post on Reddit contribute most to what subreddit it belongs to?_\n",
    "\n",
    "Your method for acquiring the data will be scraping threads from at least two subreddits. \n",
    "\n",
    "Once you've got the data, you will build a classification model that, using Natural Language Processing and any other relevant features, predicts which subreddit a given post belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Getting Data\n",
    "\n",
    "I used extractor.py contained in this folder to extract data, using the starter code instructions as a guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in Data, Last Cleaning Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskWomen</td>\n",
       "      <td>Whats your favorite podcast/what podcasts are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AskWomen</td>\n",
       "      <td>How did you stop feeling rushed into finding l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AskWomen</td>\n",
       "      <td>What’s romanticized in modern culture but real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AskWomen</td>\n",
       "      <td>What is your opinion on people referring to ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AskWomen</td>\n",
       "      <td>Introverted moms with extroverted, super talka...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                               data\n",
       "0  AskWomen  Whats your favorite podcast/what podcasts are ...\n",
       "1  AskWomen  How did you stop feeling rushed into finding l...\n",
       "2  AskWomen  What’s romanticized in modern culture but real...\n",
       "3  AskWomen  What is your opinion on people referring to ad...\n",
       "4  AskWomen  Introverted moms with extroverted, super talka..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/data_cleaned.csv')\n",
    "data.drop('Unnamed: 0', inplace = True, axis =1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['human'] = np.where(data['subreddit'] == 'AskWomen', 1, 0)\n",
    "data['text'] = data['data']\n",
    "data.drop(['data', 'subreddit'], inplace = True, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = list(data['text'])\n",
    "y = data['human']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39586485123550175"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()\n",
    "#Not overly unbalanced at .39586"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out any non-alphanumeric chars.\n",
    "import regex as re\n",
    "for i in range(len(X)):\n",
    "    X[i] = re.sub(r'[^a-zA-Z0-9]', \" \", X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3960995292535306 0.3951612903225806\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y)\n",
    "print(y_train.mean(), y_test.mean())\n",
    "#Good split based on means (makes sense since stratified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "## NLP\n",
    "\n",
    "#### Use `CountVectorizer` or `TfidfVectorizer` from scikit-learn to create features from the thread titles and descriptions (NOTE: Not all threads have a description)\n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate your models using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvec_model(X_train, y_train, m, n):\n",
    "    # initiate model\n",
    "    print('n-gram range:', m, 'to', n)\n",
    "    cvec = CountVectorizer(analyzer = 'word', ngram_range = (m, n)\n",
    "    cvec.fit(X_train, y_train)\n",
    "    \n",
    "    # transform data\n",
    "    X_train_cvec = cvec.transform(X_train)\n",
    "    X_test_cvec = cvec.transform(X_test)\n",
    "\n",
    "    # define regression\n",
    "    log_reg_cvec = LogisticRegression(penalty='l1')\n",
    "    print('Cross Val Score:', cross_val_score(log_reg_cvec, X_train_cvec, y_train).mean())\n",
    "\n",
    "    # use GridSearchCV to optimize log reg\n",
    "    parameters = {'C': np.logspace(0, 3, 10)}\n",
    "    best_log = GridSearchCV(log_reg_cvec, parameters)\n",
    "    \n",
    "    # fit and score regression\n",
    "    log_reg_cvec.fit(X_train_cvec, y_train)\n",
    "    print('Model Accuracy:', log_reg_cvec.score(X_test_cvec, y_test), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check range of n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram range: 1 to 1\n",
      "Cross Val Score: 0.7760746295957563\n",
      "Model Accuracy: 0.7782258064516129 \n",
      "\n",
      "n-gram range: 1 to 2\n",
      "Cross Val Score: 0.7706928439322805\n",
      "Model Accuracy: 0.7862903225806451 \n",
      "\n",
      "n-gram range: 1 to 3\n",
      "Cross Val Score: 0.7706928439322805\n",
      "Model Accuracy: 0.7862903225806451 \n",
      "\n",
      "n-gram range: 1 to 4\n",
      "Cross Val Score: 0.7706928439322805\n",
      "Model Accuracy: 0.7862903225806451 \n",
      "\n",
      "n-gram range: 2 to 1\n",
      "Cross Val Score: 0.7760746295957563\n",
      "Model Accuracy: 0.7782258064516129 \n",
      "\n",
      "n-gram range: 2 to 2\n",
      "Cross Val Score: 0.6139828872223239\n",
      "Model Accuracy: 0.6229838709677419 \n",
      "\n",
      "n-gram range: 2 to 3\n",
      "Cross Val Score: 0.6159976695187963\n",
      "Model Accuracy: 0.6229838709677419 \n",
      "\n",
      "n-gram range: 2 to 4\n",
      "Cross Val Score: 0.6173417610037328\n",
      "Model Accuracy: 0.6270161290322581 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in range(1, 3):\n",
    "    for n in range(1, 5):\n",
    "        cvec_model(X_train, y_train, m, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model score stays around the same value through the models. Seems to have a ceiling around .87 or .88.  \n",
    "NB: The values currently are with a GridSearchCV optimizer and lasso penalty, but scored higher on both with other set that is contained in power point information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try TD-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvec_model(X_train, y_train, m, n):\n",
    "    # initiate model\n",
    "    print('n-gram range:', m, 'to', n)\n",
    "    tvec = TfidfVectorizer(analyzer = 'word', ngram_range= (m, n),\n",
    "                          stop_words = 'english')\n",
    "    tvec.fit(X_train, y_train)\n",
    "    \n",
    "    # transform data\n",
    "    X_train_tvec = tvec.transform(X_train)\n",
    "    X_test_tvec = tvec.transform(X_test)\n",
    "    \n",
    "    # define regression\n",
    "    log_reg_tvec = LogisticRegression(penalty='l1')\n",
    "    print('Cross Val Score:', cross_val_score(log_reg_tvec, X_train_tvec, y_train).mean())\n",
    "\n",
    "    # use GridSearchCV to optimize log reg\n",
    "    parameters = {'C': np.logspace(0, 3, 10)}\n",
    "    best_log = GridSearchCV(log_reg_tvec, parameters)\n",
    "    \n",
    "    # fit and score regression\n",
    "    log_reg_tvec.fit(X_train_tvec, y_train)\n",
    "    print(\"Model Accuracy:\", log_reg_tvec.score(X_test_tvec, y_test), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check range of n-gram values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram range: 1 to 1\n",
      "Cross Val Score: 0.7329905358074372\n",
      "Model Accuracy: 0.7681451612903226 \n",
      "\n",
      "n-gram range: 1 to 2\n",
      "Cross Val Score: 0.665123400334668\n",
      "Model Accuracy: 0.6713709677419355 \n",
      "\n",
      "n-gram range: 1 to 3\n",
      "Cross Val Score: 0.6644472897994024\n",
      "Model Accuracy: 0.6733870967741935 \n",
      "\n",
      "n-gram range: 1 to 4\n",
      "Cross Val Score: 0.659073633721521\n",
      "Model Accuracy: 0.6754032258064516 \n",
      "\n",
      "n-gram range: 1 to 5\n",
      "Cross Val Score: 0.6577322520984493\n",
      "Model Accuracy: 0.6713709677419355 \n",
      "\n",
      "n-gram range: 2 to 1\n",
      "Cross Val Score: 0.7329905358074372\n",
      "Model Accuracy: 0.7681451612903226 \n",
      "\n",
      "n-gram range: 2 to 2\n",
      "Cross Val Score: 0.6119708147877162\n",
      "Model Accuracy: 0.6088709677419355 \n",
      "\n",
      "n-gram range: 2 to 3\n",
      "Cross Val Score: 0.6052476475011687\n",
      "Model Accuracy: 0.6088709677419355 \n",
      "\n",
      "n-gram range: 2 to 4\n",
      "Cross Val Score: 0.604574246827768\n",
      "Model Accuracy: 0.6088709677419355 \n",
      "\n",
      "n-gram range: 2 to 5\n",
      "Cross Val Score: 0.6039008461543673\n",
      "Model Accuracy: 0.6088709677419355 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in range(1, 3):\n",
    "    for n in range(1, 6):\n",
    "        tvec_model(X_train, y_train, m, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar range again for the models. No breaking .9 on any of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "##  Trying Decision Trees and Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree w/ Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and fit CV model to use data in others.\n",
    "cvec_final = CountVectorizer(ngram_range=(1,3))\n",
    "cv_model = cvec_final.fit(X_train, y_train)\n",
    "\n",
    "#transform X data\n",
    "cv_train = cvec_final.transform(X_train)\n",
    "cv_test = cvec_final.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 1.0\n",
      "Model Accuracy: 0.8689516129032258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# build and initial test\n",
    "dt_tree = DecisionTreeClassifier()\n",
    "\n",
    "# fit baseline model\n",
    "dt_tree.fit(cv_train, y_train)\n",
    "print('Model Accuracy:', dt_tree.score(cv_train, y_train))\n",
    "print('Model Accuracy:', dt_tree.score(cv_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use grid search for parameters check\n",
    "params = {'max_depth': range(60, 90, 3),\n",
    "          'max_leaf_nodes': range(2, 10, 2)}\n",
    "dt = GridSearchCV(dt_tree, params)\n",
    "best = dt.fit(cv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 60, 'max_leaf_nodes': 8}\n",
      "0.8412911903160726\n"
     ]
    }
   ],
   "source": [
    "print(best.best_params_)\n",
    "print(best.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8480161398789509\n",
      "Model Accuracy: 0.8608870967741935\n"
     ]
    }
   ],
   "source": [
    "# run with GridSearch results\n",
    "dt_opt = DecisionTreeClassifier(max_depth=60,\n",
    "                                max_leaf_nodes = 8)\n",
    "dt_opt.fit(cv_train, y_train)\n",
    "\n",
    "print('Model Accuracy:', dt_opt.score(cv_train, y_train))\n",
    "print('Model Accuracy:', dt_opt.score(cv_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Score: 0.8601196404013306\n"
     ]
    }
   ],
   "source": [
    "## Random Forest Classifier Model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "print(\"Cross Val Score:\", cross_val_score(rf, cv_train, y_train).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Model Accuracy: 0.995965030262273\n",
      "Test Model Accuracy: 0.8528225806451613\n"
     ]
    }
   ],
   "source": [
    "# fit and run baseline model\n",
    "rf.fit(cv_train, y_train)\n",
    "print(\"Train Model Accuracy:\", rf.score(cv_train, y_train))\n",
    "print(\"Test Model Accuracy:\", rf.score(cv_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 12, 'max_leaf_nodes': 14, 'n_estimators': 40}\n",
      "0.7935440484196369\n"
     ]
    }
   ],
   "source": [
    "# use grid search for parameters check\n",
    "params = {'n_estimators': range(10, 60, 5),\n",
    "          'max_depth': range(10, 20, 2),\n",
    "          'max_leaf_nodes': range(10, 15, 1)}\n",
    "\n",
    "rf_best = GridSearchCV(rf, params)\n",
    "rf_best.fit(cv_train, y_train)\n",
    "\n",
    "#report results\n",
    "print(rf_best.best_params_)\n",
    "print(rf_best.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Model Accuracy: 0.8298587760591796\n",
      "Test Model Accuracy: 0.8084677419354839\n"
     ]
    }
   ],
   "source": [
    "# run model with grid search params\n",
    "rf_opt = RandomForestClassifier(n_estimators=40,\n",
    "                                max_leaf_nodes=14,\n",
    "                                max_depth = 12)\n",
    "\n",
    "rf_opt.fit(cv_train, y_train)\n",
    "\n",
    "print(\"Train Model Accuracy:\", rf_opt.score(cv_train, y_train))\n",
    "print(\"Test Model Accuracy:\", rf_opt.score(cv_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on Train Data: 1.0\n",
      "Score on Test Data: 0.7681451612903226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexz\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "# Multinomial NB, using the Count Vec with n-gram (1, 3) and stop words INCLUDED\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Baseline model\n",
    "#initiate MNB model and feed transformed data\n",
    "reddit_classify_model = MultinomialNB(alpha=0)\n",
    "reddit_classify_model.fit(cv_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Score on Train Data:\", reddit_classify_model.score(cv_train, y_train))\n",
    "print(\"Score on Test Data:\", reddit_classify_model.score(cv_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[269  55]\n",
      " [ 31 141]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_hat = reddit_classify_model.predict(cv_test)\n",
    "print(confusion_matrix(y_hat, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "---\n",
    "Put your executive summary in a Markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
